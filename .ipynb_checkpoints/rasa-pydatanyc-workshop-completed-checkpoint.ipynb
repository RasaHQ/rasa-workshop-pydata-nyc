{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Going beyond 'Sorry, I didn't get that': building AI assistants that scale using machine learning\n",
    "![alt text](https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcTaX3LNhGcAe1HnPZSuWS0oH6af0LJHXcH7If1sQgLCFAT1chNGFg)\n",
    "\n",
    "\n",
    "This notebook contains the code of the workshop which I did at PyData NYC 2018. If you have any questions or would like to learn more about anything included in this notebook, please raise an issue on this repo or shoot me an email at juste@rasa.com.\n",
    "\n",
    "In this workshop you are going to build an assistant which will help you search for scientific papers easier!\n",
    "\n",
    "\n",
    "This workshop consists of four main parts:\n",
    "\n",
    "\n",
    "*   Part 0: Installation and setup\n",
    "*   Part 1: Teaching an assistant to understand user inputs using Rasa NLU model\n",
    "*   Part 2: Teaching an assistant to handle multi-turn conversations using dialogue management model.\n",
    "*   Part 3: Improving the assistant using the real-time user feedback and interactive learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 0: Installation\n",
    "\n",
    "### Let's start with jupyter configuration\n",
    "\n",
    "The code block below makes sure that you get some information which you can use for debugging, cleans up the output from unecessary warnings and defines a function which whill print json outputs in a nicely formatted way."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import logging, io, json, warnings\n",
    "logging.basicConfig(level=\"INFO\")\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "def pprint(o):\n",
    "    # small helper to make dict dumps a bit prettier\n",
    "    print(json.dumps(o, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Installation of Rasa Stack\n",
    "To complete this exercise you will need only two libraries - Rasa NLU and Rasa Core. If you have them already installed, you can skip this step, but make sure that your Ras NLU and Rasa Core versions are compatible with the ones used in this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "python = sys.executable\n",
    "\n",
    "# In your environment run:\n",
    "!{python} -m pip install -U rasa_core==0.11.11 rasa_nlu==0.13.6;\n",
    "!{python} -m pip install sklearn_crfsuite;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before moving on, let's test the installation - you should have rasa_nlu: 0.13.6 and rasa_core: 0.11.11 installed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import rasa_nlu\n",
    "import rasa_core\n",
    "\n",
    "\n",
    "print(\"rasa_nlu: {} rasa_core: {}\".format(rasa_nlu.__version__, rasa_core.__version__))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Install graphviz (recommended for Linux or Mac users)\n",
    "During this exercise we are going to create some visualiztions which user graphviz. If you have diffiulties installing it on your machine, don't worry - you will be shown the output during the workshop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!apt-get -qq install -y graphviz libgraphviz-dev pkg-config;\n",
    "!breq install graphviz\n",
    "!{python} -m pip install pygraphviz;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Natural Language Understanding\n",
    "\n",
    "At first, let's teach our chatbot how to understand user inputs. To do that, we are going to build a Rasa NLU model which will parse user inputs and perform intent classification and entity extraction tasks. To train a Rasa NLU model we will need some real conversational data. Below, we have two possible conversations between the user and the assistant which we are going to use as the basis of training data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Conversation_1:**   \n",
    "U: Hello.  \n",
    "B: Hello! I am a papers search assistant. How can I help?  \n",
    "U: I am looking for interesting papers about mathematics.  \n",
    "B: I found 'Mathematics Theory'. Would you like to read the paper? I can send you a link.  \n",
    "U: Yes, please.  \n",
    "B: Here is a link https://link_to_paper.com.  \n",
    "U: Thanks.  \n",
    "B: Happy reading.  \n",
    "U: Goodbye.  \n",
    "B: Goodbye.  \n",
    "\n",
    "\n",
    "**Conversation_2:**  \n",
    "U: Hi    \n",
    "B: Hello! I am a papers search assistant. How can I help?   \n",
    "U: I am looking for interesting papers to read  \n",
    "B: What type of papers are you interested in?  \n",
    "U: About Physics  \n",
    "B: I found 'Physics Theory'. Would you like to read the paper? I can send you a link.    \n",
    "U: Sure. Can you also show tell who are authors of this paper?  \n",
    "B: One moment please.  \n",
    "B: This is the link: https://link_to_paper.com.  \n",
    "B: The authors are xyz  \n",
    "U: Thanks.  \n",
    "B: Happy reading!  \n",
    "U: Goodbye.  \n",
    "B: Goodbye.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating the training data for language understanding model\n",
    "\n",
    "\n",
    "Lets create some training data here by grouping user messages by their `intents`. The intent describes what the messages *mean*. Another important part of training data are `entities` - pieces of information which help a chatbot understand what specifically a user is asking about. Entities are labeled using the markdown link syntex: `[entity value](entity_type)` [More information about the data format](https://rasa.com/docs/nlu/dataformat/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlu_md = \"\"\"\n",
    "\n",
    "## intent:greet\n",
    "- hey\n",
    "- hello there\n",
    "- hi\n",
    "- hello there\n",
    "- good morning\n",
    "- good evening\n",
    "- moin\n",
    "- hey there\n",
    "- let's go\n",
    "- hey dude\n",
    "- goodmorning\n",
    "- goodevening\n",
    "- good afternoon\n",
    "\n",
    "## intent:goodbye\n",
    "- cu\n",
    "- good by\n",
    "- cee you later\n",
    "- good night\n",
    "- good afternoon\n",
    "- bye\n",
    "- goodbye\n",
    "- have a nice day\n",
    "- see you around\n",
    "- bye bye\n",
    "- see you later\n",
    "\n",
    "## intent:affirm\n",
    "- yes\n",
    "- indeed\n",
    "- of course\n",
    "- that sounds good\n",
    "- correct\n",
    "- definitely\n",
    "- absolutely\n",
    "- sure\n",
    "- yep\n",
    "\n",
    "## intent:deny\n",
    "- no\n",
    "- never\n",
    "- I don't think so\n",
    "- don't like that\n",
    "- no way\n",
    "- not really\n",
    "- nope\n",
    "- definitely no\n",
    "- no no\n",
    "\n",
    "\n",
    "## intent:paper_search\n",
    "- Looking for papers about [chatbots](paper_type)\n",
    "- Please suggest some interesting papers to read\n",
    "- Looking for some new papers about [machine learning](paper_type)\n",
    "- Any recommendataions for [statistics](paper_type) papers to read?\n",
    "- I have some spare time and would like to read some [mathematics](paper_type) papers.\n",
    "- Looking for papers to read\n",
    "- Do you have new papers to recommend?\n",
    "- Would like to read some papers about [physics](paper_type).\n",
    "- Please recommend some interesting papers about [astronomy](paper_type).\n",
    "- Looking for [econometrics](paper_type) papers.\n",
    "- Looking for papers in [artificial intelligence](paper_type)\n",
    "- Please share some papers to read\n",
    "- Looking for [Physics](paper_type) to read.\n",
    "- Can you recommend me [Mathematics](paper_type)?\n",
    "- Any interesting papers [statistics](paper_type) you can recommend?\n",
    "\n",
    "\n",
    "## intent:affirm+authors\n",
    "- Yes. Also, tell me who are the authors.\n",
    "- Yes, please. By the way, who are the authors of the paper?\n",
    "- Sure. I woud also like to know the authors.\n",
    "- Yes! And a list of authors please.\n",
    "- Definitely. Also, please share who are the authors.\n",
    "- Yes. Can I also see who the authors are?\n",
    "- Sure. Also, please tell me who are the authors.\n",
    "- Sure. Can you give me a list of authors as well?\n",
    "- Yes. Tell me who wrote this paper as well.\n",
    "- Sure. Who wrote this paper?\n",
    "- Sounds good. I am also interested in who wrote this paper?\n",
    "\n",
    "## intent:authors\n",
    "- Tell me who are the authors first\n",
    "- Please tell me the who are the authors\n",
    "- I would like to see who are the authors first\n",
    "- Before I decide I would like to see the authors\n",
    "- Show me the authors please\n",
    "- Can I see the authors first?\n",
    "- Who wrote this paper?\n",
    "- I would like to know who is the author of this paper.\n",
    "- Tell me who wrote the paper.\n",
    "- Who is the author?\n",
    "- Do you know who is the author of the paper?\n",
    "- Who wrote it?\n",
    "- Do you know the author?\n",
    "\n",
    "## intent:send_link\n",
    "- Send me a link to the paper\n",
    "- Can I get a link\n",
    "- Send me a link\n",
    "- Please send me a link so I can read it\n",
    "- Send me a link to it please\n",
    "- I would like to get a link\n",
    "\n",
    "## intent:inform\n",
    "- about [statistics](paper_type)\n",
    "- maybe [mathematics](paper_type)\n",
    "- about [geography](paper_type)\n",
    "- for [machine learning](paper_type)\n",
    "- about [differentiation](paper_type)\n",
    "- maybe about [calculus](paper_type)\n",
    "\n",
    "## intent:thanks\n",
    "- thanks\n",
    "- thank you\n",
    "- thank you very much\n",
    "- thanks a lot\n",
    "- thank you so much\n",
    "- thank you loads\n",
    "\"\"\"\n",
    "\n",
    "%store nlu_md > nlu.md"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining the NLU model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once the training data is ready, we can define our NLU model. We can do that by constructing the processing pipeline which defines how structured data is extracted from unstructured user inputs. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = \"\"\"\n",
    "language: \"en\"\n",
    "\n",
    "pipeline:\n",
    "- name: \"tokenizer_whitespace\"                              #defines how unstructured sentences will be tokenized\n",
    "- name: \"ner_crf\"                                           #defines the model which will be used for entity extraction\n",
    "- name: \"intent_featurizer_count_vectors\"                   #creates sentence representation\n",
    "- name: \"intent_classifier_tensorflow_embedding\"            #defines a classifier for intent classification\n",
    "  intent_tokenization_flag: true                            #sets the flag for intent label tokenization\n",
    "  intent_split_symbol: \"+\"                                  #defines the character on which intent labels should be tokenized\n",
    "\"\"\" \n",
    "\n",
    "%store config > config.yml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training the Rasa NLU Model\n",
    "\n",
    "We're going to train a model to recognise user inputs, so that when you send a message like \"hello\" to your bot, it will recognise this as a `\"greet\"` intent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rasa_nlu.training_data import load_data\n",
    "from rasa_nlu.config import RasaNLUModelConfig\n",
    "from rasa_nlu.model import Trainer\n",
    "from rasa_nlu import config\n",
    "\n",
    "# loading the nlu training samples\n",
    "training_data = load_data(\"nlu.md\")\n",
    "\n",
    "# trainer to educate our pipeline\n",
    "trainer = Trainer(config.load(\"config.yml\"))\n",
    "\n",
    "# train the model!\n",
    "interpreter = trainer.train(training_data, verbose=True)\n",
    "\n",
    "# store it for future use\n",
    "model_directory = trainer.persist(\"./models/nlu\", fixed_model_name=\"current\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using & evaluating the NLU model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see how the model is performing on some of the inputs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pprint(interpreter.parse(\"Who are the authors?\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instead of evaluating it by hand, the model can also be evaluated on a test data set (though for simplicity we are going to use the same for test and train):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rasa_nlu.evaluate import run_evaluation\n",
    "import IPython\n",
    "from IPython import display\n",
    "\n",
    "run_evaluation(\"nlu.md\", model_directory)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 2: Handling the dialogue"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have taught our assistant how to understand user inputs. Now, it's time to teach it how to make responses by training a dialogue management model using Rasa Core."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Writing Stories\n",
    "\n",
    "The training data for dialogue management models is called `stories`. A story is an actual conversation where user inputs are expressed as intents as well as corresponding entities, and chatbot responses are expressed as actions.\n",
    "\n",
    "\n",
    "Let's take a look into the format of the stories in more detail:\n",
    "\n",
    "A story starts with `##` and you can give it a name. \n",
    "Lines that start with `*` are messages sent by the user. Although you don't write the *actual* message, but rather the intent (and the entities) that represent what the user *means*. \n",
    "Lines that start with `-` are *actions* taken by your bot. In this case all of our actions are just messages sent back to the user, like `utter_greet`, but in general an action can do anything, including calling an API and interacting with the outside world. \n",
    "\n",
    "To start generating some training data, let's use the original conversations between the user and the assistant again: \n",
    "\n",
    "**Conversation_1:**   \n",
    "U: Hello.  \n",
    "B: Hello! I am a papers search assistant. How can I help?  \n",
    "U: I am looking for interesting papers about mathematics.  \n",
    "B: I found 'Mathematics Theory'. Would you like to read the paper? I can send you a link.  \n",
    "U: Yes, please.  \n",
    "B: Here is a link https://link_to_paper.com.  \n",
    "U: Thanks.  \n",
    "B: Happy reading.  \n",
    "U: Goodbye.  \n",
    "B: Goodbye.  \n",
    "\n",
    "\n",
    "**Conversation_2:**  \n",
    "U: Hi    \n",
    "B: Hello! I am a papers search assistant. How can I help?   \n",
    "U: I am looking for interesting papers to read  \n",
    "B: What type of papers are you interested in?  \n",
    "U: About Physics  \n",
    "B: I found 'Physics Theory'. Would you like to read the paper? I can send you a link.    \n",
    "U: Sure. Can you also show tell who are authors of this paper?  \n",
    "B: One moment please.  \n",
    "B: This is the link: https://link_to_paper.com.  \n",
    "B: The authors are xyz  \n",
    "U: Thanks.  \n",
    "B: Happy reading!  \n",
    "U: Goodbye.  \n",
    "B: Goodbye.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stories_md = \"\"\"\n",
    "\n",
    "\n",
    "## Suggestion path 1\n",
    "* greet\n",
    "  - utter_greet\n",
    "* paper_search\n",
    "  - utter_what_type\n",
    "* inform{\"paper_type\":\"machine learning\"}\n",
    "  - action_paper_search\n",
    "  - utter_approve\n",
    "* affirm\n",
    "  - utter_send_link\n",
    "* goodbye\n",
    "  - utter_goodbye\n",
    "\n",
    "## Suggestion path 2\n",
    "* greet\n",
    "  - utter_greet\n",
    "* paper_search{\"paper_type\":\"chatbots\"}\n",
    "  - action_paper_search\n",
    "  - utter_approve\n",
    "* affirm+authors\n",
    "  - utter_send_link\n",
    "  - utter_authors\n",
    "* thanks\n",
    "  - utter_happy_reading\n",
    "* goodbye\n",
    "  - utter_goodbye\n",
    "\n",
    "## Suggestion path 3\n",
    "* greet\n",
    "  - utter_greet\n",
    "* paper_search{\"paper_type\":\"statistics\"}\n",
    "  - action_paper_search\n",
    "  - utter_approve\n",
    "* deny\n",
    "  - utter_goodbye\n",
    "  \n",
    "## Suggestion path 4\n",
    "* greet\n",
    "  - utter_greet\n",
    "* paper_search{\"paper_type\":\"statistics\"}\n",
    "  - action_paper_search\n",
    "  - utter_approve\n",
    "* affirm\n",
    "  - utter_send_link\n",
    "* authors\n",
    "  - utter_authors\n",
    "* thanks\n",
    "  - utter_happy_reading\n",
    "* goodbye\n",
    "  -utter_goodbye\n",
    "  \n",
    "\n",
    "## Suggestion path 5\n",
    "* greet\n",
    "  - utter_greet\n",
    "* paper_search{\"paper_type\":\"mathematics\"}\n",
    "  - action_paper_search\n",
    "  - utter_approve\n",
    "* authors\n",
    "  - utter_authors\n",
    "* send_link\n",
    "  - utter_send_link\n",
    "* goodbye\n",
    "  -utter_goodbye\n",
    "  \n",
    "  \n",
    "## Suggestion path 6\n",
    "* greet\n",
    "  - utter_greet\n",
    "* paper_search\n",
    "  - utter_what_type\n",
    "* inform{\"paper_type\":\"chatbots\"}\n",
    "  - action_paper_search\n",
    "  - utter_approve\n",
    "* authors\n",
    "  - utter_authors\n",
    "* send_link\n",
    "  - utter_send_link\n",
    "* thanks\n",
    "  - utter_happy_reading\n",
    "* goodbye\n",
    "  -utter_goodbye \n",
    "  \n",
    "  \n",
    "## Suggestion path 7\n",
    "* greet\n",
    "  - utter_greet\n",
    "* paper_search\n",
    "  - utter_what_type\n",
    "* inform{\"paper_type\":\"chatbots\"}\n",
    "  - action_paper_search\n",
    "  - utter_approve\n",
    "* affirm+authors\n",
    "  - utter_send_link\n",
    "  - utter_authors\n",
    "* thanks\n",
    "  - utter_happy_reading\n",
    "* goodbye\n",
    "  -utter_goodbye \n",
    "  \n",
    "  \n",
    "## Suggestion path 8\n",
    "* greet\n",
    "  - utter_greet\n",
    "* paper_search\n",
    "  - utter_what_type\n",
    "* inform{\"paper_type\":\"statistics\"}\n",
    "  - action_paper_search\n",
    "  - utter_approve\n",
    "* affirm+authors\n",
    "  - utter_send_link\n",
    "  - utter_authors\n",
    "* thanks\n",
    "  - utter_happy_reading\n",
    "* goodbye\n",
    "  -utter_goodbye   \n",
    "\n",
    "\n",
    "## Suggestion path 9\n",
    "* greet\n",
    "  - utter_greet\n",
    "* paper_search{\"paper_type\":\"physics\"}\n",
    "  - action_paper_search\n",
    "  - utter_approve\n",
    "* affirm\n",
    "  - utter_send_link\n",
    "* authors\n",
    "  - utter_authors\n",
    "* thanks\n",
    "  - utter_happy_reading\n",
    "* goodbye\n",
    "  -utter_goodbye \n",
    "\n",
    "\"\"\"\n",
    "\n",
    "%store stories_md > stories.md\n",
    "\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining a Domain\n",
    "\n",
    "The domain specifies the universe that the assistant operates in. In AI assistant's world this universe consists of intents and entities as well as the actions which appear in training stories. The domain can also contain the templates for the answers an assistant should use to respond to the user and slots which will help the assistant to keep track of the context. Let's look into the domain of our bot:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "domain_yml = \"\"\"\n",
    "\n",
    "intents:\n",
    "- greet\n",
    "- goodbye\n",
    "- paper_search\n",
    "- inform\n",
    "- affirm\n",
    "- affirm+authors\n",
    "- authors\n",
    "- thanks\n",
    "- deny\n",
    "- send_link\n",
    "\n",
    "slots:\n",
    "  paper_type:\n",
    "    type: text\n",
    "  link:\n",
    "    type: text\n",
    "  authors:\n",
    "    type: text\n",
    "    \n",
    "entities:\n",
    "- paper_type\n",
    "\n",
    "actions:\n",
    "- utter_greet\n",
    "- utter_goodbye\n",
    "- utter_send_link\n",
    "- utter_what_type\n",
    "- utter_happy_reading\n",
    "- utter_authors\n",
    "- utter_approve\n",
    "- action_paper_search\n",
    "\n",
    "templates:\n",
    "  utter_greet:\n",
    "  - text: \"Hey! I am paper search assistant. How can I help\"\n",
    "\n",
    "  utter_goodbye:\n",
    "  - text: \"Have a great day!\"\n",
    "\n",
    "  utter_send_link:\n",
    "  - text: \"Here is a link: {link}\"\n",
    "  \n",
    "  utter_what_type:\n",
    "  - text: \"What type of paper would you like me to find?\"\n",
    "  \n",
    "  utter_happy_reading:\n",
    "  - text: \"Enjoy your reading.\"\n",
    "  \n",
    "  utter_approve:\n",
    "  - text: \"Would you like to read this paper? I can send you a link.\"\n",
    "  \n",
    "  utter_authors:\n",
    "  - text: \"Here is a list of authors: {authors}.\"\n",
    "\"\"\"\n",
    "\n",
    "%store domain_yml > domain.yml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adding Custom Actions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The responses of the assistant can be more than just simple text responses - it can call an API to retrieve some data which can later be used to create a response to user input. Let's create a custom action for our bot which, when predicted, will make an API and a look for a paper to suggest based on user request. Since we save entities as slots, out assistant will know which specific paper it should look for."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_action = \"\"\"\n",
    "\n",
    "from rasa_core_sdk import Action\n",
    "from rasa_core_sdk.events import SlotSet\n",
    "\n",
    "import requests\n",
    "\n",
    "class ApiAction(Action):\n",
    "    def name(self):\n",
    "        return \"action_paper_search\"\n",
    "\n",
    "    def run(self, dispatcher, tracker, domain):\n",
    "\n",
    "        paper_type = tracker.get_slot('paper_type')\n",
    "        \n",
    "        response = requests.get('http://dblp.org/search/publ/api?q={}&format=json&h=1'.format(paper_type)).json()\n",
    "        title = response['result']['hits']['hit'][0]['info']['title']\n",
    "        authors = response['result']['hits']['hit'][0]['info']['authors']['author'][0]\n",
    "        link = response['result']['hits']['hit'][0]['info']['url']\n",
    "\n",
    "        dispatcher.utter_message(\"I found a paper called {}\".format(title))\n",
    "        return [SlotSet(\"link\",link), SlotSet(\"authors\",authors)]\n",
    "        \n",
    "\"\"\"\n",
    "%store custom_action > actions.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pro tip: visualizing the training data\n",
    "Another good way to debug your training data is to visualize the training stories and inspect the conversation turns it is going to cover."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image\n",
    "from rasa_core.agent import Agent\n",
    "\n",
    "agent = Agent('domain.yml')\n",
    "agent.visualize(\"stories.md\", \"story_graph.png\", max_history=2)\n",
    "Image(filename=\"story_graph.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training your Dialogue Model\n",
    "\n",
    "Now we are good to train the dialogue management model. We can specify what policies should be used to train it - in this case, the model is a neural network implemented in Keras which learns to predict which action to take next. We can also tweak the parameters of what percentage of training examples should be used for validation and how many epochs should be used for training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rasa_core.policies import KerasPolicy, MemoizationPolicy\n",
    "from rasa_core.agent import Agent\n",
    "\n",
    "# there is a threshold for the NLU predictions as well as the action predictions\n",
    "\n",
    "agent = Agent('domain.yml', policies=[MemoizationPolicy(), KerasPolicy()])\n",
    "\n",
    "# loading our neatly defined training dialogues\n",
    "training_data = agent.load_data('stories.md')\n",
    "\n",
    "agent.train(\n",
    "    training_data,\n",
    "    validation_split=0.0,\n",
    "    epochs=200\n",
    ")\n",
    "\n",
    "agent.persist('models/dialogue')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing the assistant!\n",
    "\n",
    "Congratulations! You have just trained the dialogue management model of your assistant which means that you are ready to test your assistant.\n",
    "\n",
    "The code block below defines the webhook configuration of the action server:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "endpoint = \"\"\"\n",
    "action_endpoint:\n",
    "  url: \"http://localhost:5055/webhook\"\n",
    "\"\"\"\n",
    "%store endpoint > endpoints.yml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You will have to start the actions server on the command line. To do that, use code block below  to start the command line and run the following command: **python -m rasa_core_sdk.endpoint --actions actions**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import IFrame\n",
    "IFrame(\"http://localhost:8888/terminals/1\", width=1000, height=500)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Talking to the Bot (with NLU)\n",
    "\n",
    "Now it's time to test the assistant. The code below will launch the start_action_server and run_bot functions in parallel and will launch the assistant for you to test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import IPython\n",
    "from IPython.display import clear_output\n",
    "from rasa_core.agent import Agent\n",
    "from rasa_core.interpreter import NaturalLanguageInterpreter\n",
    "from rasa_core.utils import EndpointConfig\n",
    "import time\n",
    "\n",
    "messages = [\"Hi! you can chat in this window. Type 'stop' to end the conversation.\"]\n",
    "interpreter = NaturalLanguageInterpreter.create('models/current/nlu')\n",
    "endpoint = EndpointConfig('http://localhost:5055/webhook')\n",
    "agent = Agent.load('models/dialogue', interpreter=interpreter, action_endpoint = endpoint)\n",
    "\n",
    "print(\"Your bot is ready to talk! Type your messages here or send 'stop'\")\n",
    "while True:\n",
    "    a = input()\n",
    "    if a == 'stop':\n",
    "        break\n",
    "    responses = agent.handle_text(a)\n",
    "    for response in responses:\n",
    "        print(response[\"text\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation of the dialogue model\n",
    "As with the NLU model, instead of just subjectively testing the model, we can also evaluate the model on a dataset. You'll be using the training data set again, but usually you'd use a test data set separate from the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!{python} -m rasa_core.evaluate -d models/dialogue -s stories.md -o matrix.pdf --failed failed_stories.md"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interactive learning\n",
    "To start an interactive learning session, we will use a command line inside the jupyter again. Once the terminal is open, you can start the session by running: **python -m rasa_core.train --online -o models/dialogue -d domain.yml -s stories.md -u models/nlu/default/current --endpoints endpoints.yml**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import IFrame\n",
    "IFrame(\"http://localhost:8888/terminals/2\", width=1000, height=500)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tips\n",
    "\n",
    "- Bootstrap from little conversational data and allow users to use your application early on.\n",
    "- Use interactive learning to start generating training data and training your model.\n",
    "- Connect your assistant to the outside world by using the most popular messaging or voice platforms."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Resources \n",
    "- [Official Rasa documentation](https://rasa.com/docs/getting-started/overview/)\n",
    "- [Rasa Community Forum](https://forum.rasa.com)\n",
    "- [Supervised vord vectors from scratch in Rasa NLU](https://medium.com/rasa-blog/supervised-word-vectors-from-scratch-in-rasa-nlu-6daf794efcd8)\n",
    "- [How to handle multiple intents per input using Rasa NLU TensorFlow pipeline](https://medium.com/rasa-blog/how-to-handle-multiple-intents-per-input-using-rasa-nlu-tensorflow-pipeline-75698b49c383)\n",
    "- [Going beyond ‘Hey Google’: building a Rasa-powered Google Assistant](https://medium.com/rasa-blog/going-beyond-hey-google-building-a-rasa-powered-google-assistant-5ff916409a25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
